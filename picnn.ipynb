{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, scipy\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.manual_seed(0)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Gradient(nn.Module):\n",
    "    '''A network block that output the gradient by the displace u\n",
    "        The input is (batch, 2, N*N), the channels are for displacement [ux, uy] \n",
    "        The output is (batch, 4, Ngrad):[ux_1, uy_1, ux_2, uy_2]\n",
    "    '''\n",
    "    def __init__(self, Gradx, Grady):\n",
    "        super().__init__()\n",
    "        self.Gradx = Gradx\n",
    "        self.Grady = Grady\n",
    "    def forward(self, x):\n",
    "        gx = torch.einsum('lk, ijk -> ijl', self.Gradx, x)\n",
    "        gy = torch.einsum('lk, ijk -> ijl', self.Grady, x)\n",
    "        return torch.cat((gx, gy), dim=1)\n",
    "\n",
    "class InnerEnergy(nn.Module):\n",
    "    '''A network block that output the inner energy\n",
    "        The input is (batch, 4, Ngrad) and (batch, N*N), the first argument is for displacement gradient, \n",
    "        the last one is for  Young's modulus \n",
    "        The output is (batch,)\n",
    "    '''\n",
    "    def __init__(self, CG2DG, Vitg):\n",
    "        super().__init__()\n",
    "        self.CG2DG = CG2DG\n",
    "        self.Vitg = Vitg\n",
    "    def forward(self, x, E):\n",
    "        Em = torch.einsum('ij, kj -> ki', self.CG2DG, E)\n",
    "        nu = 0.3\n",
    "        nu1, nu2 = 1.0/(2*(1 + nu)), nu/((1 + nu)*(1 - 2*nu))\n",
    "        mu, lmbda = Em*nu1, Em*nu2\n",
    "        J = (1+x[:,0,:])*(1+x[:,3,:]) - x[:,1,:]*x[:,2,:]\n",
    "        Ic = (1+x[:,0,:])**2 + (1+x[:,3,:])**2 + x[:,1,:]**2 + x[:,2,:]**2\n",
    "        psi = 0.5*mu*(Ic - 2) - mu*torch.log(J) + 0.5*lmbda*((torch.log(J))**2)\n",
    "        Psi = torch.einsum('j, ij -> i', self.Vitg, psi)\n",
    "        return Psi\n",
    "    \n",
    "class OuterEnergy(nn.Module):\n",
    "    '''A network block that output the inner energy\n",
    "        The input is (batch, 2, N*N), the channels are for displacement [ux, uy] \n",
    "        The output is (batch,)\n",
    "    '''\n",
    "    def __init__(self, S_X, S_Y):\n",
    "        super().__init__()\n",
    "        self.S_X = S_X\n",
    "        self.S_Y = S_Y\n",
    "    def forward(self, x):\n",
    "        xx = x[:,0,...].reshape((x.shape[0],-1))\n",
    "        xy = x[:,1,...].reshape((x.shape[0],-1))\n",
    "        ox = torch.einsum('j, ij -> i', self.S_X, xx)\n",
    "        oy = torch.einsum('j, ij -> i', self.S_Y, xy)\n",
    "        return ox + oy\n",
    "\n",
    "class SED(nn.Module):\n",
    "    '''A network block that output the strain energy density by the displace u and Young's modulus\n",
    "        The input is (batch, 2, N, N) and (batch, N, N), the first argument is for displacement, \n",
    "        the last one is for  Young's modulus\n",
    "    '''\n",
    "    def __init__(self, Gradx, Grady, CG2DG, Vitg, S_X, S_Y):\n",
    "        super().__init__()\n",
    "        self.CG2DG = CG2DG\n",
    "        self.Vitg = Vitg\n",
    "        self.S_X = S_X\n",
    "        self.S_Y = S_Y\n",
    "        self.Grad = Gradient(Gradx, Grady)   \n",
    "        self.Inner = InnerEnergy(CG2DG, Vitg)\n",
    "        self.Outer = OuterEnergy(S_X, S_Y)\n",
    "    def forward(self, x, E):\n",
    "        xr = x.reshape((x.shape[0], x.shape[1], -1))\n",
    "        Em = (95.0*E + 5.0).reshape((E.shape[0], -1))\n",
    "        xg = self.Grad(xr)\n",
    "        IPsi = self.Inner(xg, Em)\n",
    "        OPsi = self.Outer(xr)\n",
    "        return IPsi + OPsi\n",
    "        \n",
    "class Dirichlet(nn.Module):\n",
    "    '''A network block that output the boundary sum of the Dirichlet boundary\n",
    "        The input is (batch, 2, N, N)\n",
    "        The output is (batch,)\n",
    "    '''      \n",
    "    def __init__(self, Mfix):\n",
    "        super().__init__()\n",
    "        self.Mfix = Mfix\n",
    "    def forward(self, x):\n",
    "        xr = x.reshape((x.shape[0], x.shape[1], -1))\n",
    "        diri = torch.einsum('ij, klj -> kli', self.Mfix, xr)\n",
    "        return torch.sum(torch.square(diri), (1,2))\n",
    "    \n",
    "class Observe(nn.Module):\n",
    "    '''A network block that output the observation\n",
    "        The input is (batch, 2, N, N)\n",
    "        The output is (batch, 2, Nobs)\n",
    "    '''      \n",
    "    def __init__(self, Mobs):\n",
    "        super().__init__()\n",
    "        self.Mobs = Mobs\n",
    "    def forward(self, x):\n",
    "        xr = x.reshape((x.shape[0], x.shape[1], -1))\n",
    "        obs = torch.einsum('ij, klj -> kli', self.Mobs, xr)\n",
    "        return obs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_244/3602341371.py:4: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  A2N, N2A, Ma2n, Mn2a, Mobs, Mfix, CG2DG, Gradx, Grady, Vitg, S_X, S_Y = pickle.load(file)\n",
      "/tmp/ipykernel_244/3602341371.py:4: DeprecationWarning: Please use `lil_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.lil` namespace is deprecated.\n",
      "  A2N, N2A, Ma2n, Mn2a, Mobs, Mfix, CG2DG, Gradx, Grady, Vitg, S_X, S_Y = pickle.load(file)\n"
     ]
    }
   ],
   "source": [
    "import os, pickle\n",
    "\n",
    "with open(os.path.join(os.path.abspath('.'), 'KnownData', 'Losscomp' + '.pickle'), 'rb') as file:\n",
    "    A2N, N2A, Ma2n, Mn2a, Mobs, Mfix, CG2DG, Gradx, Grady, Vitg, S_X, S_Y = pickle.load(file)\n",
    "    \n",
    "with open(os.path.join(os.path.abspath('.'), 'KnownData', 'ParaSam' + '.pickle'), 'rb') as file:\n",
    "    sam, Tsam = pickle.load(file)\n",
    "\n",
    "with open(os.path.join(os.path.abspath('.'), 'KnownData', 'USam' + '.pickle'), 'rb') as file:\n",
    "    u_sam, obs_sam = pickle.load(file)\n",
    "\n",
    "with open(os.path.join(os.path.abspath('.'), 'KnownData', 'UTSam' + '.pickle'), 'rb') as file:\n",
    "    u_Tsam, obs_Tsam = pickle.load(file)\n",
    "    \n",
    "with open(os.path.join(os.path.abspath('.'), 'KnownData', 'ParaSam_ve' + '.pickle'), 'rb') as file:\n",
    "    sam_ve = pickle.load(file)\n",
    "\n",
    "sam = torch.from_numpy(sam).float()\n",
    "Tsam = torch.from_numpy(Tsam).float() \n",
    "u_sam = torch.from_numpy(u_sam).float()\n",
    "obs_sam = torch.from_numpy(obs_sam).float()\n",
    "u_Tsam = torch.from_numpy(u_Tsam).float()\n",
    "obs_Tsam = torch.from_numpy(obs_Tsam).float()\n",
    "\n",
    "\n",
    "Mobst = torch.from_numpy(Mobs.todense()).float().to(device)\n",
    "Mfixt = torch.from_numpy(Mfix.todense()).float().to(device)\n",
    "CG2DGt = torch.from_numpy(CG2DG).float().to(device)\n",
    "Gradxt = torch.from_numpy(Gradx).float().to(device)\n",
    "Gradyt = torch.from_numpy(Grady).float().to(device)\n",
    "Vitgt = torch.from_numpy(Vitg).float().to(device)\n",
    "S_Xt = torch.from_numpy(S_X).float().to(device)\n",
    "S_Yt = torch.from_numpy(S_Y).float().to(device)\n",
    "\n",
    "u = u_sam[112:114,...].clone()\n",
    "uobs = obs_sam[112:114,...].clone()\n",
    "E = sam[112:114,0,...].clone()\n",
    "\n",
    "ut = u.to(device)\n",
    "uobst = uobs.to(device)\n",
    "Et = E.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sed = SED(Gradxt, Gradyt, CG2DGt, Vitgt, S_Xt, S_Yt).to(device)\n",
    "diri = Dirichlet(Mfixt).to(device)\n",
    "obs = Observe(Mobst).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sed(ut, Et))\n",
    "# print(diri(ut)*10000)\n",
    "# print(obs(ut)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(u, E):\n",
    "    ux = u[0,...].reshape(-1)\n",
    "    uy = u[1,...].reshape(-1)\n",
    "    guxm = Gradx.dot(ux)\n",
    "    guym = Grady.dot(ux)\n",
    "    gvxm = Gradx.dot(uy)\n",
    "    gvym = Grady.dot(uy)\n",
    "    Em = E.reshape(-1)\n",
    "    Em = Em*95.0 + 5.0\n",
    "    Em = CG2DG.dot(Em)\n",
    "    psi = np.zeros(Em.shape[0])\n",
    "    for i in range(guxm.shape[0]):\n",
    "        J = (1+guxm[i])*(1+gvym[i]) - guym[i]*gvxm[i]\n",
    "        Ic = (1+guxm[i])**2 + (1+gvym[i])**2 + guym[i]**2 + gvxm[i]**2\n",
    "        nu = 0.3\n",
    "        mu, lmbda = Em[i]/(2*(1 + nu)), Em[i]*nu/((1 + nu)*(1 - 2*nu))\n",
    "        psi[i] = (mu/2)*(Ic - 2) - mu*np.log(J) + (lmbda/2)*(np.log(J))**2\n",
    "    Psi = np.dot(Vitg, psi) + np.dot(S_X, ux) + np.dot(S_Y, uy)\n",
    "    dirux = Mfix.dot(ux)\n",
    "    diruy = Mfix.dot(uy)\n",
    "    dirv = np.square(dirux).sum() + np.square(diruy).sum()\n",
    "    obsux = Mobs.dot(ux)\n",
    "    obsuy = Mobs.dot(uy)\n",
    "    print(Psi)\n",
    "    print(dirv*10000)\n",
    "    # print(obsux*100)\n",
    "    # print(obsuy*100)\n",
    "# test(u[0,...], E[0,...])\n",
    "# test(u[1,...], E[1,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_sed(u, E):\n",
    "    Es = torch.squeeze(E, 1)\n",
    "    ls = sed(u*0.01, Es)*100\n",
    "    ld = diri(u)\n",
    "    return torch.mean(ls) + torch.mean(ld)\n",
    "\n",
    "def loss_sup(u, u_ref, u_obs):\n",
    "    la = (u-u_ref)**2\n",
    "    la = torch.mean(la.reshape(la.shape[0], -1), dim=-1)\n",
    "    lobs = (obs(u)-u_obs)**2\n",
    "    lobs = torch.mean(lobs.reshape(lobs.shape[0], -1), dim=-1)\n",
    "    return torch.mean(la+lobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1097, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "uran = torch.randn(ut.shape).to(device)*0.01-0.03\n",
    "print(loss_sed(uran, Et))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiasLayer(torch.nn.Module):\n",
    "    def __init__(self, shape) -> None:\n",
    "        super().__init__()\n",
    "        bias_value = torch.randn(shape)\n",
    "        self.bias_layer = torch.nn.Parameter(bias_value)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.bias_layer[None, ...]\n",
    "\n",
    "class PICNN(nn.Module):\n",
    "    '''A convolution neural network to approximate the forward model.'''\n",
    "    def __init__(self, resolution=32, channels=[1, 1, 2, 2, 4, 4, 8, 8, 16, 16, 8, 8, 4, 4, 2, 2], *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.N = resolution\n",
    "        self.Np = resolution*resolution\n",
    "        self.channels = channels\n",
    "        #self.fc1 = nn.Conv2d(channels[0], channels[0], kernel_size=3, stride=1,\n",
    "        #                     padding=1, bias=True)\n",
    "        self.fc1 = BiasLayer((channels[0], self.N, self.N))\n",
    "        self.conv1 = nn.Conv2d(channels[0], channels[1], kernel_size=9, stride=1, \n",
    "                               padding=4, bias=True)\n",
    "        self.conv2 = nn.Conv2d(channels[1], channels[2], kernel_size=9, stride=1, \n",
    "                               padding=4, bias=True)\n",
    "        self.res1 = nn.Conv2d(channels[0], channels[2], kernel_size=1, stride=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(channels[2], channels[3], kernel_size=9, stride=1, \n",
    "                               padding=4, bias=True)\n",
    "        self.conv4 = nn.Conv2d(channels[3], channels[4], kernel_size=9, stride=1, \n",
    "                               padding=4, bias=True)\n",
    "        self.res2 = nn.Conv2d(channels[2], channels[4], kernel_size=1, stride=1)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(channels[4], channels[5], kernel_size=9, stride=1, \n",
    "                               padding=4, bias=True)\n",
    "        self.conv6 = nn.Conv2d(channels[5], channels[6], kernel_size=9, stride=1, \n",
    "                               padding=4, bias=True)\n",
    "        self.res3 = nn.Conv2d(channels[4], channels[6], kernel_size=1, stride=1)\n",
    "        self.pool6 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.conv7 = nn.Conv2d(channels[6], channels[7], kernel_size=9, stride=1, \n",
    "                               padding=4, bias=True)\n",
    "        self.conv8 = nn.Conv2d(channels[7], channels[8], kernel_size=9, stride=1, \n",
    "                               padding=4, bias=True)\n",
    "        self.res4 = nn.Conv2d(channels[6], channels[8], kernel_size=1, stride=1)\n",
    "        self.pool8 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.conv9 = nn.Conv2d(channels[8], channels[9], kernel_size=9, stride=1, \n",
    "                               padding=4, bias=True)\n",
    "        self.conv10 = nn.Conv2d(channels[9], channels[10], kernel_size=9, stride=1, \n",
    "                               padding=4, bias=True)\n",
    "        self.res5 = nn.Conv2d(channels[8], channels[10], kernel_size=1, stride=1)\n",
    "        self.pool10 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.conv11 = nn.Conv2d(channels[10], channels[11], kernel_size=9, stride=1, \n",
    "                               padding=4, bias=True)\n",
    "        self.conv12 = nn.Conv2d(channels[11], channels[12], kernel_size=9, stride=1, \n",
    "                               padding=4, bias=True)\n",
    "        self.res6 = nn.Conv2d(channels[10], channels[12], kernel_size=1, stride=1)\n",
    "        self.pool12 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.conv13 = nn.Conv2d(channels[12], channels[13], kernel_size=9, stride=1, \n",
    "                               padding=4, bias=True)\n",
    "        self.conv14 = nn.Conv2d(channels[13], channels[14], kernel_size=9, stride=1, \n",
    "                               padding=4, bias=True)\n",
    "        self.res7 = nn.Conv2d(channels[12], channels[14], kernel_size=1, stride=1)\n",
    "        self.pool14 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.conv15 = nn.Conv2d(channels[14], channels[15], kernel_size=9, stride=1, \n",
    "                               padding=4, bias=True)\n",
    "        self.fc16 = nn.Conv2d(channels[15], channels[15], kernel_size=1, stride=1,\n",
    "                              padding=0, bias=True)\n",
    "        #self.fc16 = BiasLayer((channels[15], self.N, self.N))\n",
    "        self.act = nn.SiLU()\n",
    "    def forward(self, x):\n",
    "        y = self.act(self.fc1(x))\n",
    "        y_ = self.conv2(self.act(self.conv1(y)))\n",
    "        y = self.act(y_ + self.res1(y))\n",
    "        # y = self.pool2(y)\n",
    "        y_ = self.conv4(self.act(self.conv3(y)))\n",
    "        y = self.act(y_ + self.res2(y))\n",
    "        # y = self.pool4(y)\n",
    "        y_ = self.conv6(self.act(self.conv5(y)))\n",
    "        y = self.act(y_ + self.res3(y))\n",
    "        # y = self.pool6(y)\n",
    "        y_ = self.conv8(self.act(self.conv7(y)))\n",
    "        y = self.act(y_ + self.res4(y))\n",
    "        # y = self.pool8(y)\n",
    "        y_ = self.conv10(self.act(self.conv9(y)))\n",
    "        y = self.act(y_ + self.res5(y))\n",
    "        # y = self.pool10(y)\n",
    "        y_ = self.conv12(self.act(self.conv11(y)))\n",
    "        y = self.act(y_ + self.res6(y))\n",
    "        # y = self.pool12(y)\n",
    "        y_ = self.conv14(self.act(self.conv13(y)))\n",
    "        y = self.act(y_ + self.res7(y))\n",
    "        # y = self.pool14(y)\n",
    "        y = self.act(self.conv15(y))\n",
    "        y= self.fc16(y)\n",
    "        return y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "configfw = {  \n",
    "            'n_epochsup': 1500, # number of training epochs for supervised learning\n",
    "            'n_epochuns': 250, # number of training epochs for unsupervised learning\n",
    "            'n_epochsem': 400, # number of training epochs for semisupervised learning\n",
    "            'batch_size': 32, # size of a mini-batch\n",
    "            'learning_rate': 1.8e-3, # learning rate\n",
    "            'learning_rate_sem': 5e-5, # learning rate for semisupervised learning\n",
    "            'ema_decay': 0.999, # decay rate for Exponential Moving Average \n",
    "            'lr_decay': 0.9,\n",
    "            'lr_threshold': 1e-5,\n",
    "            'lr_min': 5e-5,\n",
    "            'lr_min_sem': 5e-6\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import trange\n",
    "class FM():\n",
    "    '''The forward model'''\n",
    "    def __init__(self, pdeloss, suploss, Mobst, config) -> None:\n",
    "        self.network = PICNN().to(device)\n",
    "        self.obs = Observe(Mobst).to(device)\n",
    "        self.pdeloss = pdeloss\n",
    "        self.suploss = suploss\n",
    "        self.n_epochsup = config['n_epochsup']\n",
    "        self.n_epochuns = config['n_epochuns']\n",
    "        self.n_epochsem = config['n_epochsem']\n",
    "        self.batch_size = config['batch_size']\n",
    "        self.lr = config['learning_rate']\n",
    "        self.lr_s = config['learning_rate_sem']\n",
    "        self.config = config\n",
    "    def load_para_sup(self):\n",
    "        self.network.load_state_dict(torch.load(os.path.join(os.path.abspath('.'), 'NNfw_para_sup.pth')))\n",
    "        self.network.eval()\n",
    "    def load_para_uns(self):\n",
    "        self.network.load_state_dict(torch.load(os.path.join(os.path.abspath('.'), 'NNfw_para_uns.pth')))\n",
    "        self.network.eval()\n",
    "    def load_para(self):\n",
    "        self.network.load_state_dict(torch.load(os.path.join(os.path.abspath('.'), 'NNfw_para.pth')))\n",
    "        self.network.eval()\n",
    "    def evaluate(self, E):\n",
    "        self.network.eval()\n",
    "        if E.dim() == 2:\n",
    "            Et  = E[None,None,...]\n",
    "        elif E.dim() == 3:\n",
    "            Et = E[:,None,...]\n",
    "        else:\n",
    "            Et = E\n",
    "        return self.network(Et)*0.01\n",
    "    def observe(self, E):\n",
    "        u = self.evaluate(E)\n",
    "        return self.obs(u)\n",
    "    def derivative(self, E):\n",
    "        self.network.eval()\n",
    "        Et = E.reshape(-1)\n",
    "        Et.requires_grad_(True)\n",
    "        Er = Et.reshape((1,1,self.network.N, self.network.N))\n",
    "        J = torch.empty(self.obs.Mobs.shape[0], self.network.Np)\n",
    "        obs = self.obs(self.network(Er))\n",
    "        obs.reshape(-1)\n",
    "        for i in range(obs.shape[0]):\n",
    "            obs[0,i].backward(retain_graph=True)\n",
    "            t = Et.grad\n",
    "            J[i,:] = t[0,:]\n",
    "            Et.grad.data.zero_()\n",
    "        return J\n",
    "    def supervised_train(self, dataset):\n",
    "        data_loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "        optimizer = Adam(self.network.parameters(), lr=self.lr)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=self.config['lr_decay'], patience=120, \n",
    "                                      threshold=self.config['lr_threshold'], threshold_mode='rel', \n",
    "                                      cooldown=200, min_lr=self.config['lr_min'])\n",
    "        tqdm_epoch = trange(self.n_epochsup)\n",
    "        \n",
    "        self.network.train()\n",
    "        for epoch in tqdm_epoch:\n",
    "            avg_loss = 0.\n",
    "            num_items = 0\n",
    "            for x, y, z in data_loader:\n",
    "                x = torch.tensor(x, device=device) # x.to(device) \n",
    "                y = torch.tensor(y, device=device)\n",
    "                z = torch.tensor(z, device=device)\n",
    "                yp = self.network(x)   \n",
    "                loss = self.suploss(yp, y, z)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()    \n",
    "                optimizer.step()\n",
    "                scheduler.step(loss)\n",
    "                avg_loss += loss.item() * x.shape[0]\n",
    "                num_items += x.shape[0]\n",
    "            # Print the averaged training loss so far.\n",
    "            tqdm_epoch.set_description('Average Loss: {:5f}'.format(avg_loss / num_items * 1000))\n",
    "            # Update the checkpoint after each epoch of training.\n",
    "            torch.save(self.network.state_dict(), 'NNfw_para_sup.pth')\n",
    "        self.network.eval() \n",
    "    def unsupervised_train(self, dataset):\n",
    "        data_loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "        optimizer = Adam(self.network.parameters(), lr=self.lr)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=self.config['lr_decay'], patience=120, \n",
    "                                      threshold=self.config['lr_threshold'], threshold_mode='rel', \n",
    "                                      cooldown=200, min_lr=self.config['lr_min'])\n",
    "        tqdm_epoch = trange(self.n_epochuns)\n",
    "        \n",
    "        self.network.train()\n",
    "        n = 0\n",
    "        for epoch in tqdm_epoch:\n",
    "            avg_loss = 0.\n",
    "            num_items = 0\n",
    "            for x, y in data_loader:\n",
    "                n+=1\n",
    "                x = torch.tensor(x, device=device) # x.to(device)   \n",
    "                yp = self.network(x)    \n",
    "                loss = self.pdeloss(yp, x)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()    \n",
    "                optimizer.step()\n",
    "                scheduler.step(loss)\n",
    "                avg_loss += loss.item() * x.shape[0]\n",
    "                num_items += x.shape[0]\n",
    "            # Print the averaged training loss so far.\n",
    "            tqdm_epoch.set_description('Average Loss: {:5f}'.format(avg_loss / num_items * 10))\n",
    "            # Update the checkpoint after each epoch of training.\n",
    "            torch.save(self.network.state_dict(), 'NNfw_para_uns.pth')\n",
    "        self.network.eval()   \n",
    "    def semisupervised_train(self, dataset_sup, dataset_uns, if_pretrained = True):\n",
    "        data_loader_sup = DataLoader(dataset_sup, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "        data_loader_uns = DataLoader(dataset_uns, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "        if if_pretrained:\n",
    "            optimizer = Adam(self.network.parameters(), lr=self.lr_s)\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=self.config['lr_decay'], patience=120, \n",
    "                                        threshold=self.config['lr_threshold'], threshold_mode='rel', \n",
    "                                        cooldown=200, min_lr=self.config['lr_min_sem'])\n",
    "        else:\n",
    "            optimizer = Adam(self.network.parameters(), lr=self.lr)\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=self.config['lr_decay'], patience=120, \n",
    "                                        threshold=self.config['lr_threshold'], threshold_mode='rel', \n",
    "                                        cooldown=200, min_lr=self.config['lr_min'])\n",
    "        tqdm_epoch = trange(self.n_epochsem)\n",
    "        \n",
    "        self.network.train()\n",
    "        dataloader_iterator = iter(data_loader_sup)\n",
    "        for epoch in tqdm_epoch:\n",
    "            avg_loss = 0.\n",
    "            avg_loss1 = 0.\n",
    "            num_items = 0\n",
    "            num_items1 = 0\n",
    "            for x, y in data_loader_uns:\n",
    "                try:\n",
    "                    x1, y1, z1 = next(dataloader_iterator)\n",
    "                except StopIteration:\n",
    "                    dataloader_iterator = iter(data_loader_sup)\n",
    "                    avg_loss1 = 0.\n",
    "                    num_items1 = 0\n",
    "                    x1, y1, z1 = next(dataloader_iterator)\n",
    "                x = torch.tensor(x, device=device) # x.to(device) \n",
    "                x1 = torch.tensor(x1, device=device)   \n",
    "                y1 = torch.tensor(y1, device=device)   \n",
    "                z1 = torch.tensor(z1, device=device)  \n",
    "                yp = self.network(x)  \n",
    "                yp1 = self.network(x1)  \n",
    "                loss = self.pdeloss(yp, x)\n",
    "                loss1 = self.suploss(yp1, y1, z1)\n",
    "                losst = 5*loss1 + 0.05*loss\n",
    "                optimizer.zero_grad()\n",
    "                losst.backward()    \n",
    "                optimizer.step()\n",
    "                scheduler.step(losst)\n",
    "                avg_loss += loss.item() * x.shape[0]\n",
    "                avg_loss1 += loss1.item() * x1.shape[0]\n",
    "                num_items += x.shape[0]\n",
    "                num_items1 += x1.shape[0]\n",
    "            tqdm_epoch.set_description('Average Loss: {:5f} = {:5f} + {:5f}'.format(\n",
    "                (avg_loss/num_items+avg_loss1/num_items1)*1000, avg_loss/num_items*10, avg_loss1/num_items1*1000))\n",
    "            torch.save(self.network.state_dict(), 'NNfw_para.pth')\n",
    "        self.network.eval() \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "Forward_Model = FM(loss_sed, loss_sup, Mobst, configfw)\n",
    "dataset_sup = TensorDataset(sam[:u_sam.shape[0],...], u_sam*100, obs_sam*100)\n",
    "sam_uns = torch.cat((sam, sam_ve), 0)\n",
    "sam_uns = sam_uns.clamp(0.0, 1.0)\n",
    "dataset_uns = TensorDataset(sam_uns[:2**15], torch.empty(2**15))\n",
    "#Forward_Model.supervised_train(dataset_sup)\n",
    "#Forward_Model.load_para_sup()\n",
    "#Forward_Model.unsupervised_train(dataset_uns)\n",
    "#Forward_Model.load_para_sup()\n",
    "#Forward_Model.semisupervised_train(dataset_sup, dataset_uns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_T = TensorDataset(Tsam, u_Tsam*100, obs_Tsam*100)\n",
    "def test_FM(Forward_Model, dataset):\n",
    "    data_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "    Forward_Model.network.eval()\n",
    "    avg_loss = 0.\n",
    "    num_items = 0\n",
    "    i = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y, z in data_loader:\n",
    "            x = torch.tensor(x, device=device) # x.to(device) \n",
    "            y = torch.tensor(y, device=device)\n",
    "            z = torch.tensor(z, device=device)\n",
    "            yp = Forward_Model.network(x)   \n",
    "            loss = loss_sup(yp, y, z)\n",
    "            avg_loss += loss.item() * x.shape[0]\n",
    "            num_items += x.shape[0]\n",
    "            op = obs(yp)\n",
    "            if i == 0:\n",
    "                diff = (op - z).cpu()\n",
    "            else:\n",
    "                dif = (op - z).cpu()\n",
    "                diff = torch.cat((diff, dif), 0)\n",
    "            i += 1\n",
    "        qtl = torch.tensor([0.95, 0.5, 0.05])\n",
    "        err_mean = torch.sqrt(torch.mean(diff**2, 0))\n",
    "        err_std = torch.std(diff, 0)\n",
    "        err_max = torch.sqrt(torch.amax(diff**2, 0))\n",
    "        err_min = torch.sqrt(torch.amin(diff**2, 0))\n",
    "        err_q = torch.sqrt(torch.quantile(diff**2, qtl, dim=0))\n",
    "        print('Average Test Loss: {:5f}'.format(avg_loss/num_items * 1000))\n",
    "        print(err_mean)\n",
    "        print(err_std)\n",
    "        print(err_max)\n",
    "        print(err_min)\n",
    "        print(err_q)\n",
    "    return torch.mean(err_mean), torch.mean(err_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_244/1859510098.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x, device=device) # x.to(device)\n",
      "/tmp/ipykernel_244/1859510098.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=device)\n",
      "/tmp/ipykernel_244/1859510098.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  z = torch.tensor(z, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss: 3.567199\n",
      "tensor([[0.0172, 0.0069, 0.0196, 0.0080, 0.0183, 0.0097, 0.0103, 0.0132, 0.0175,\n",
      "         0.0139, 0.0138, 0.0133, 0.0131, 0.0148, 0.0135, 0.0156, 0.0147, 0.0161,\n",
      "         0.0156, 0.0172, 0.0165, 0.0170, 0.0174, 0.0174, 0.0193, 0.0184, 0.0220,\n",
      "         0.0194, 0.0255, 0.0210, 0.0301, 0.0230, 0.0345, 0.0263, 0.0380, 0.0310,\n",
      "         0.0391, 0.0375, 0.0430, 0.0399, 0.0454, 0.0413, 0.0448, 0.0436, 0.0448,\n",
      "         0.0460, 0.0469, 0.0503, 0.0506, 0.0538, 0.0538, 0.0588, 0.0576, 0.0655,\n",
      "         0.0618, 0.0678, 0.0617, 0.0710, 0.0645, 0.0796, 0.0809, 0.0740, 0.0743,\n",
      "         0.0722, 0.0661, 0.0647, 0.0643, 0.0628, 0.0619, 0.0600, 0.0597, 0.0582,\n",
      "         0.0557, 0.0525, 0.0523, 0.0527, 0.0524, 0.0517, 0.0527, 0.0538, 0.0562,\n",
      "         0.0591, 0.0600, 0.0598, 0.0609, 0.0616, 0.0619, 0.0671, 0.0707, 0.0740,\n",
      "         0.0783, 0.0977],\n",
      "        [0.0261, 0.0205, 0.0283, 0.0234, 0.0252, 0.0218, 0.0153, 0.0191, 0.0196,\n",
      "         0.0177, 0.0153, 0.0175, 0.0173, 0.0159, 0.0192, 0.0166, 0.0200, 0.0177,\n",
      "         0.0212, 0.0189, 0.0223, 0.0203, 0.0243, 0.0220, 0.0269, 0.0232, 0.0296,\n",
      "         0.0246, 0.0328, 0.0272, 0.0363, 0.0309, 0.0391, 0.0335, 0.0393, 0.0337,\n",
      "         0.0393, 0.0341, 0.0384, 0.0363, 0.0391, 0.0389, 0.0412, 0.0414, 0.0431,\n",
      "         0.0427, 0.0452, 0.0441, 0.0470, 0.0469, 0.0486, 0.0492, 0.0492, 0.0521,\n",
      "         0.0518, 0.0572, 0.0564, 0.0614, 0.0614, 0.0672, 0.0695, 0.0454, 0.0413,\n",
      "         0.0405, 0.0449, 0.0432, 0.0468, 0.0451, 0.0442, 0.0441, 0.0444, 0.0436,\n",
      "         0.0453, 0.0472, 0.0443, 0.0367, 0.0332, 0.0362, 0.0391, 0.0402, 0.0384,\n",
      "         0.0382, 0.0397, 0.0438, 0.0443, 0.0447, 0.0442, 0.0456, 0.0444, 0.0500,\n",
      "         0.0529, 0.0701]])\n",
      "tensor([[0.0124, 0.0059, 0.0193, 0.0080, 0.0179, 0.0097, 0.0094, 0.0119, 0.0107,\n",
      "         0.0139, 0.0121, 0.0130, 0.0131, 0.0147, 0.0135, 0.0156, 0.0141, 0.0161,\n",
      "         0.0153, 0.0167, 0.0165, 0.0170, 0.0174, 0.0174, 0.0187, 0.0179, 0.0215,\n",
      "         0.0194, 0.0255, 0.0210, 0.0296, 0.0230, 0.0344, 0.0262, 0.0381, 0.0309,\n",
      "         0.0392, 0.0375, 0.0429, 0.0399, 0.0454, 0.0410, 0.0448, 0.0434, 0.0447,\n",
      "         0.0460, 0.0466, 0.0503, 0.0506, 0.0538, 0.0538, 0.0587, 0.0574, 0.0655,\n",
      "         0.0618, 0.0680, 0.0613, 0.0710, 0.0637, 0.0795, 0.0807, 0.0737, 0.0743,\n",
      "         0.0721, 0.0660, 0.0647, 0.0642, 0.0629, 0.0620, 0.0599, 0.0597, 0.0581,\n",
      "         0.0556, 0.0525, 0.0524, 0.0524, 0.0525, 0.0518, 0.0526, 0.0539, 0.0560,\n",
      "         0.0591, 0.0601, 0.0599, 0.0610, 0.0617, 0.0620, 0.0669, 0.0708, 0.0741,\n",
      "         0.0783, 0.0979],\n",
      "        [0.0104, 0.0121, 0.0175, 0.0192, 0.0184, 0.0198, 0.0146, 0.0182, 0.0141,\n",
      "         0.0168, 0.0153, 0.0160, 0.0173, 0.0158, 0.0191, 0.0166, 0.0200, 0.0177,\n",
      "         0.0209, 0.0189, 0.0224, 0.0204, 0.0243, 0.0218, 0.0265, 0.0230, 0.0290,\n",
      "         0.0246, 0.0320, 0.0267, 0.0356, 0.0292, 0.0386, 0.0314, 0.0390, 0.0327,\n",
      "         0.0389, 0.0338, 0.0373, 0.0358, 0.0378, 0.0378, 0.0404, 0.0406, 0.0431,\n",
      "         0.0426, 0.0451, 0.0442, 0.0459, 0.0469, 0.0473, 0.0491, 0.0493, 0.0521,\n",
      "         0.0519, 0.0560, 0.0565, 0.0604, 0.0614, 0.0670, 0.0695, 0.0455, 0.0414,\n",
      "         0.0399, 0.0448, 0.0430, 0.0468, 0.0452, 0.0438, 0.0424, 0.0442, 0.0434,\n",
      "         0.0451, 0.0470, 0.0443, 0.0366, 0.0332, 0.0362, 0.0383, 0.0386, 0.0377,\n",
      "         0.0382, 0.0391, 0.0435, 0.0442, 0.0431, 0.0442, 0.0454, 0.0444, 0.0495,\n",
      "         0.0529, 0.0701]])\n",
      "tensor([[0.0416, 0.0196, 0.0549, 0.0304, 0.0504, 0.0376, 0.0450, 0.0389, 0.0403,\n",
      "         0.0417, 0.0606, 0.0489, 0.0624, 0.0620, 0.0677, 0.0679, 0.0691, 0.0688,\n",
      "         0.0795, 0.0728, 0.0963, 0.0616, 0.1035, 0.0668, 0.1068, 0.0658, 0.1133,\n",
      "         0.0827, 0.1228, 0.0935, 0.1615, 0.1026, 0.2652, 0.1309, 0.2465, 0.1580,\n",
      "         0.2222, 0.1939, 0.2271, 0.1906, 0.2274, 0.1468, 0.1934, 0.1385, 0.1843,\n",
      "         0.1900, 0.1908, 0.1882, 0.2040, 0.2430, 0.2316, 0.3135, 0.2152, 0.3839,\n",
      "         0.2565, 0.4399, 0.2295, 0.4246, 0.2456, 0.3767, 0.4773, 0.3112, 0.3515,\n",
      "         0.3531, 0.3793, 0.3249, 0.2804, 0.3271, 0.2314, 0.2335, 0.2568, 0.2672,\n",
      "         0.2645, 0.2020, 0.1728, 0.1659, 0.1628, 0.1512, 0.1517, 0.1898, 0.2188,\n",
      "         0.2120, 0.2495, 0.2516, 0.2619, 0.2979, 0.2860, 0.2697, 0.3219, 0.3259,\n",
      "         0.3573, 0.6102],\n",
      "        [0.0487, 0.0441, 0.0670, 0.0581, 0.0680, 0.0608, 0.0631, 0.0671, 0.0735,\n",
      "         0.0688, 0.0633, 0.0683, 0.0661, 0.0629, 0.0724, 0.0624, 0.0777, 0.0707,\n",
      "         0.0784, 0.0785, 0.0865, 0.0895, 0.0961, 0.1000, 0.1251, 0.1054, 0.1606,\n",
      "         0.1114, 0.1969, 0.1234, 0.2269, 0.1356, 0.1818, 0.1496, 0.1324, 0.1622,\n",
      "         0.1560, 0.1804, 0.1360, 0.2067, 0.1332, 0.2311, 0.1260, 0.2491, 0.1442,\n",
      "         0.2613, 0.1529, 0.2713, 0.1618, 0.2817, 0.1903, 0.2759, 0.2048, 0.2461,\n",
      "         0.2250, 0.2238, 0.2448, 0.2635, 0.2587, 0.3711, 0.2316, 0.1758, 0.1469,\n",
      "         0.1742, 0.2020, 0.1987, 0.1875, 0.1968, 0.2586, 0.2441, 0.1992, 0.1677,\n",
      "         0.1507, 0.2073, 0.2135, 0.2392, 0.1196, 0.1772, 0.2178, 0.2114, 0.1581,\n",
      "         0.1592, 0.1547, 0.2011, 0.2156, 0.2340, 0.1982, 0.1810, 0.1822, 0.2243,\n",
      "         0.2906, 0.4338]])\n",
      "tensor([[7.1153e-05, 6.9782e-05, 1.0580e-05, 1.8328e-06, 1.9139e-04, 3.5375e-05,\n",
      "         2.4363e-06, 7.9282e-05, 2.6409e-04, 1.0054e-04, 9.9987e-06, 8.8926e-05,\n",
      "         1.3450e-04, 3.2425e-05, 2.7686e-05, 8.3745e-06, 1.0705e-04, 8.0109e-05,\n",
      "         3.4034e-05, 7.7486e-06, 3.2544e-05, 1.1003e-04, 1.0526e-04, 1.1027e-04,\n",
      "         4.2915e-06, 2.6941e-05, 6.2823e-05, 1.0860e-04, 5.2810e-05, 6.0201e-05,\n",
      "         1.6046e-04, 1.0169e-04, 1.5104e-04, 2.2411e-05, 7.5817e-05, 6.1440e-04,\n",
      "         7.5102e-05, 1.3947e-04, 2.0397e-04, 4.1485e-05, 7.5340e-05, 9.9897e-05,\n",
      "         6.6042e-05, 1.8668e-04, 5.5313e-05, 8.3089e-05, 2.3544e-04, 1.7846e-04,\n",
      "         7.3969e-05, 1.8692e-04, 2.0981e-05, 7.8011e-04, 4.1395e-04, 1.0747e-04,\n",
      "         1.4782e-04, 2.8849e-05, 3.7193e-04, 1.1444e-04, 1.7440e-04, 2.8515e-04,\n",
      "         3.7193e-04, 3.5787e-04, 1.8549e-04, 1.9383e-04, 3.1835e-04, 2.0862e-05,\n",
      "         5.9605e-08, 1.8382e-04, 2.8443e-04, 6.5842e-04, 2.0266e-05, 1.2815e-05,\n",
      "         5.9241e-04, 1.5408e-04, 1.4317e-04, 1.6212e-04, 8.7440e-05, 3.1495e-04,\n",
      "         8.3888e-04, 8.1003e-04, 2.8670e-04, 2.2054e-04, 3.5524e-05, 9.6679e-05,\n",
      "         2.5189e-04, 3.1185e-04, 1.4114e-04, 7.6294e-06, 1.2094e-04, 6.4659e-04,\n",
      "         3.3092e-04, 6.0153e-04],\n",
      "        [9.8959e-05, 5.0768e-05, 2.2709e-05, 4.4653e-04, 1.6925e-04, 6.8396e-05,\n",
      "         8.0526e-05, 2.7239e-05, 2.1875e-05, 4.3094e-05, 1.4722e-05, 1.4067e-05,\n",
      "         7.9632e-05, 7.2360e-05, 7.1526e-07, 3.9220e-05, 1.1969e-04, 6.2704e-05,\n",
      "         1.5128e-04, 3.7789e-05, 3.9339e-06, 6.5565e-05, 1.4424e-04, 7.6413e-05,\n",
      "         9.1553e-05, 3.8147e-06, 6.0081e-05, 1.9908e-04, 1.2994e-04, 2.8610e-05,\n",
      "         3.8314e-04, 1.7405e-04, 1.9026e-04, 1.7548e-04, 2.3007e-04, 7.1526e-07,\n",
      "         4.7731e-04, 1.1396e-04, 1.8787e-04, 3.4738e-04, 1.4782e-05, 1.7595e-04,\n",
      "         2.4557e-05, 5.8174e-05, 1.4019e-04, 1.1444e-04, 2.1744e-04, 2.9039e-04,\n",
      "         1.4925e-04, 5.2452e-05, 8.8692e-05, 8.5354e-05, 7.8201e-05, 1.9312e-05,\n",
      "         8.3923e-05, 1.3244e-04, 3.3331e-04, 2.2840e-04, 5.3120e-04, 4.6420e-04,\n",
      "         3.4404e-04, 4.8923e-04, 2.9564e-05, 7.6771e-05, 1.5736e-04, 2.0981e-05,\n",
      "         2.6703e-05, 1.4877e-04, 6.1989e-06, 1.0061e-04, 1.2875e-04, 8.1539e-05,\n",
      "         1.1492e-04, 1.0538e-04, 9.0599e-06, 6.1989e-06, 2.8563e-04, 3.3665e-04,\n",
      "         3.4332e-05, 1.1015e-04, 1.5545e-04, 2.3842e-06, 2.6226e-05, 1.0109e-04,\n",
      "         1.2708e-04, 1.4067e-04, 3.4332e-05, 2.6703e-05, 9.2030e-05, 9.5367e-06,\n",
      "         8.2970e-05, 1.7500e-04]])\n",
      "tensor([[[0.0324, 0.0140, 0.0371, 0.0155, 0.0361, 0.0203, 0.0214, 0.0258,\n",
      "          0.0285, 0.0267, 0.0295, 0.0266, 0.0262, 0.0308, 0.0268, 0.0330,\n",
      "          0.0282, 0.0319, 0.0289, 0.0308, 0.0321, 0.0305, 0.0319, 0.0311,\n",
      "          0.0368, 0.0358, 0.0422, 0.0381, 0.0513, 0.0406, 0.0563, 0.0439,\n",
      "          0.0632, 0.0528, 0.0771, 0.0618, 0.0742, 0.0730, 0.0900, 0.0882,\n",
      "          0.0898, 0.0884, 0.0915, 0.0947, 0.0867, 0.1032, 0.0940, 0.1094,\n",
      "          0.1053, 0.1114, 0.1121, 0.1157, 0.1112, 0.1260, 0.1162, 0.1414,\n",
      "          0.1268, 0.1346, 0.1397, 0.1538, 0.1461, 0.1447, 0.1413, 0.1435,\n",
      "          0.1276, 0.1241, 0.1327, 0.1193, 0.1283, 0.1262, 0.1121, 0.1150,\n",
      "          0.1174, 0.1104, 0.1094, 0.1172, 0.1182, 0.1168, 0.1145, 0.1151,\n",
      "          0.1152, 0.1207, 0.1235, 0.1245, 0.1318, 0.1355, 0.1405, 0.1521,\n",
      "          0.1602, 0.1548, 0.1618, 0.1774],\n",
      "         [0.0397, 0.0359, 0.0494, 0.0444, 0.0449, 0.0424, 0.0308, 0.0372,\n",
      "          0.0361, 0.0348, 0.0318, 0.0348, 0.0350, 0.0332, 0.0371, 0.0321,\n",
      "          0.0389, 0.0346, 0.0453, 0.0383, 0.0443, 0.0406, 0.0488, 0.0420,\n",
      "          0.0568, 0.0457, 0.0597, 0.0488, 0.0633, 0.0574, 0.0687, 0.0605,\n",
      "          0.0730, 0.0686, 0.0811, 0.0673, 0.0797, 0.0608, 0.0768, 0.0687,\n",
      "          0.0780, 0.0739, 0.0860, 0.0807, 0.0888, 0.0789, 0.0843, 0.0857,\n",
      "          0.0907, 0.0917, 0.0929, 0.0969, 0.1004, 0.1061, 0.1103, 0.1208,\n",
      "          0.1220, 0.1211, 0.1285, 0.1360, 0.1435, 0.0866, 0.0819, 0.0853,\n",
      "          0.0891, 0.0890, 0.0997, 0.0876, 0.0845, 0.0873, 0.0959, 0.0987,\n",
      "          0.1061, 0.0991, 0.0956, 0.0751, 0.0730, 0.0783, 0.0768, 0.0838,\n",
      "          0.0833, 0.0789, 0.0827, 0.0883, 0.0904, 0.0864, 0.1001, 0.0978,\n",
      "          0.0917, 0.0910, 0.0999, 0.1360]],\n",
      "\n",
      "        [[0.0129, 0.0044, 0.0133, 0.0048, 0.0122, 0.0050, 0.0058, 0.0094,\n",
      "          0.0159, 0.0094, 0.0077, 0.0094, 0.0076, 0.0086, 0.0071, 0.0093,\n",
      "          0.0089, 0.0103, 0.0097, 0.0115, 0.0094, 0.0115, 0.0107, 0.0115,\n",
      "          0.0113, 0.0124, 0.0114, 0.0124, 0.0151, 0.0131, 0.0182, 0.0150,\n",
      "          0.0179, 0.0163, 0.0177, 0.0180, 0.0192, 0.0187, 0.0236, 0.0191,\n",
      "          0.0232, 0.0220, 0.0254, 0.0235, 0.0276, 0.0232, 0.0280, 0.0250,\n",
      "          0.0281, 0.0292, 0.0310, 0.0320, 0.0330, 0.0302, 0.0399, 0.0294,\n",
      "          0.0352, 0.0321, 0.0383, 0.0399, 0.0451, 0.0431, 0.0421, 0.0413,\n",
      "          0.0372, 0.0358, 0.0376, 0.0350, 0.0391, 0.0370, 0.0344, 0.0361,\n",
      "          0.0324, 0.0294, 0.0306, 0.0285, 0.0270, 0.0278, 0.0279, 0.0321,\n",
      "          0.0313, 0.0317, 0.0311, 0.0335, 0.0279, 0.0293, 0.0323, 0.0337,\n",
      "          0.0360, 0.0362, 0.0386, 0.0432],\n",
      "         [0.0248, 0.0174, 0.0242, 0.0162, 0.0198, 0.0145, 0.0086, 0.0110,\n",
      "          0.0143, 0.0103, 0.0086, 0.0114, 0.0102, 0.0105, 0.0112, 0.0105,\n",
      "          0.0110, 0.0111, 0.0112, 0.0113, 0.0116, 0.0115, 0.0129, 0.0129,\n",
      "          0.0148, 0.0135, 0.0172, 0.0133, 0.0188, 0.0148, 0.0197, 0.0170,\n",
      "          0.0205, 0.0184, 0.0210, 0.0190, 0.0222, 0.0199, 0.0234, 0.0206,\n",
      "          0.0258, 0.0215, 0.0258, 0.0229, 0.0251, 0.0232, 0.0258, 0.0229,\n",
      "          0.0269, 0.0252, 0.0289, 0.0270, 0.0301, 0.0281, 0.0294, 0.0328,\n",
      "          0.0301, 0.0327, 0.0362, 0.0369, 0.0388, 0.0269, 0.0266, 0.0228,\n",
      "          0.0263, 0.0220, 0.0260, 0.0240, 0.0235, 0.0252, 0.0233, 0.0215,\n",
      "          0.0214, 0.0224, 0.0217, 0.0189, 0.0173, 0.0191, 0.0195, 0.0213,\n",
      "          0.0196, 0.0203, 0.0226, 0.0248, 0.0223, 0.0239, 0.0227, 0.0225,\n",
      "          0.0237, 0.0258, 0.0276, 0.0393]],\n",
      "\n",
      "        [[0.0013, 0.0007, 0.0018, 0.0003, 0.0012, 0.0004, 0.0005, 0.0011,\n",
      "          0.0026, 0.0010, 0.0007, 0.0008, 0.0011, 0.0006, 0.0006, 0.0006,\n",
      "          0.0010, 0.0008, 0.0011, 0.0008, 0.0009, 0.0013, 0.0013, 0.0010,\n",
      "          0.0007, 0.0013, 0.0007, 0.0012, 0.0009, 0.0011, 0.0025, 0.0014,\n",
      "          0.0020, 0.0019, 0.0010, 0.0021, 0.0016, 0.0019, 0.0018, 0.0016,\n",
      "          0.0021, 0.0020, 0.0026, 0.0021, 0.0034, 0.0018, 0.0031, 0.0026,\n",
      "          0.0025, 0.0027, 0.0036, 0.0041, 0.0038, 0.0050, 0.0041, 0.0056,\n",
      "          0.0046, 0.0047, 0.0024, 0.0041, 0.0067, 0.0044, 0.0039, 0.0057,\n",
      "          0.0048, 0.0025, 0.0027, 0.0034, 0.0037, 0.0032, 0.0027, 0.0025,\n",
      "          0.0050, 0.0027, 0.0025, 0.0037, 0.0025, 0.0022, 0.0030, 0.0041,\n",
      "          0.0019, 0.0024, 0.0032, 0.0046, 0.0034, 0.0025, 0.0017, 0.0019,\n",
      "          0.0040, 0.0024, 0.0035, 0.0043],\n",
      "         [0.0066, 0.0023, 0.0029, 0.0023, 0.0017, 0.0016, 0.0006, 0.0010,\n",
      "          0.0016, 0.0012, 0.0009, 0.0010, 0.0013, 0.0009, 0.0013, 0.0009,\n",
      "          0.0011, 0.0009, 0.0009, 0.0009, 0.0007, 0.0009, 0.0009, 0.0019,\n",
      "          0.0015, 0.0010, 0.0019, 0.0013, 0.0019, 0.0017, 0.0020, 0.0018,\n",
      "          0.0023, 0.0025, 0.0025, 0.0020, 0.0029, 0.0018, 0.0023, 0.0020,\n",
      "          0.0028, 0.0019, 0.0018, 0.0018, 0.0020, 0.0020, 0.0029, 0.0020,\n",
      "          0.0037, 0.0021, 0.0030, 0.0018, 0.0030, 0.0027, 0.0026, 0.0039,\n",
      "          0.0026, 0.0032, 0.0025, 0.0032, 0.0031, 0.0031, 0.0021, 0.0015,\n",
      "          0.0027, 0.0022, 0.0019, 0.0017, 0.0017, 0.0031, 0.0021, 0.0015,\n",
      "          0.0024, 0.0017, 0.0013, 0.0016, 0.0014, 0.0018, 0.0016, 0.0021,\n",
      "          0.0018, 0.0016, 0.0022, 0.0029, 0.0017, 0.0030, 0.0034, 0.0017,\n",
      "          0.0017, 0.0027, 0.0025, 0.0038]]])\n",
      "tensor(0.0401) tensor(0.0395)\n"
     ]
    }
   ],
   "source": [
    "Forward_Model.load_para()\n",
    "err_mean, err_std = test_FM(Forward_Model, dataset_T)\n",
    "print(err_mean, err_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss: 5.315718\n",
      "tensor([[0.0127, 0.0072, 0.0164, 0.0092, 0.0133, 0.0135, 0.0111, 0.0142, 0.0185,\n",
      "         0.0136, 0.0144, 0.0216, 0.0162, 0.0175, 0.0152, 0.0167, 0.0162, 0.0178,\n",
      "         0.0173, 0.0222, 0.0192, 0.0212, 0.0199, 0.0219, 0.0216, 0.0223, 0.0253,\n",
      "         0.0267, 0.0317, 0.0289, 0.0376, 0.0308, 0.0413, 0.0343, 0.0445, 0.0390,\n",
      "         0.0484, 0.0478, 0.0527, 0.0509, 0.0544, 0.0503, 0.0543, 0.0533, 0.0544,\n",
      "         0.0560, 0.0561, 0.0607, 0.0597, 0.0650, 0.0597, 0.0690, 0.0646, 0.0790,\n",
      "         0.0688, 0.0803, 0.0718, 0.0864, 0.0779, 0.0966, 0.0992, 0.0890, 0.0958,\n",
      "         0.0866, 0.0810, 0.0768, 0.0759, 0.0752, 0.0720, 0.0727, 0.0688, 0.0713,\n",
      "         0.0685, 0.0674, 0.0672, 0.0636, 0.0627, 0.0651, 0.0666, 0.0681, 0.0696,\n",
      "         0.0749, 0.0750, 0.0770, 0.0792, 0.0789, 0.0784, 0.0869, 0.0848, 0.0899,\n",
      "         0.0972, 0.1209],\n",
      "        [0.0191, 0.0145, 0.0273, 0.0185, 0.0264, 0.0200, 0.0152, 0.0180, 0.0192,\n",
      "         0.0187, 0.0167, 0.0194, 0.0182, 0.0185, 0.0200, 0.0199, 0.0219, 0.0210,\n",
      "         0.0232, 0.0219, 0.0252, 0.0230, 0.0275, 0.0242, 0.0300, 0.0259, 0.0325,\n",
      "         0.0284, 0.0364, 0.0315, 0.0419, 0.0347, 0.0468, 0.0371, 0.0478, 0.0384,\n",
      "         0.0478, 0.0399, 0.0449, 0.0420, 0.0438, 0.0441, 0.0458, 0.0469, 0.0495,\n",
      "         0.0510, 0.0539, 0.0546, 0.0628, 0.0588, 0.0635, 0.0616, 0.0655, 0.0652,\n",
      "         0.0656, 0.0699, 0.0754, 0.0776, 0.0777, 0.0832, 0.0843, 0.0628, 0.0557,\n",
      "         0.0559, 0.0499, 0.0610, 0.0589, 0.0535, 0.0509, 0.0478, 0.0512, 0.0495,\n",
      "         0.0525, 0.0569, 0.0554, 0.0449, 0.0415, 0.0420, 0.0432, 0.0456, 0.0452,\n",
      "         0.0465, 0.0475, 0.0515, 0.0542, 0.0504, 0.0523, 0.0525, 0.0532, 0.0588,\n",
      "         0.0650, 0.0828]])\n",
      "tensor([[0.0099, 0.0068, 0.0153, 0.0078, 0.0126, 0.0094, 0.0106, 0.0113, 0.0132,\n",
      "         0.0134, 0.0141, 0.0129, 0.0144, 0.0147, 0.0152, 0.0162, 0.0160, 0.0167,\n",
      "         0.0173, 0.0177, 0.0190, 0.0192, 0.0199, 0.0204, 0.0216, 0.0215, 0.0250,\n",
      "         0.0237, 0.0302, 0.0265, 0.0359, 0.0296, 0.0406, 0.0328, 0.0435, 0.0373,\n",
      "         0.0463, 0.0441, 0.0514, 0.0472, 0.0531, 0.0491, 0.0533, 0.0522, 0.0520,\n",
      "         0.0542, 0.0521, 0.0591, 0.0565, 0.0638, 0.0573, 0.0686, 0.0606, 0.0783,\n",
      "         0.0667, 0.0797, 0.0693, 0.0858, 0.0740, 0.0956, 0.0974, 0.0867, 0.0951,\n",
      "         0.0845, 0.0782, 0.0745, 0.0721, 0.0713, 0.0680, 0.0646, 0.0651, 0.0658,\n",
      "         0.0649, 0.0627, 0.0624, 0.0612, 0.0589, 0.0603, 0.0619, 0.0638, 0.0671,\n",
      "         0.0723, 0.0718, 0.0729, 0.0763, 0.0761, 0.0759, 0.0821, 0.0822, 0.0875,\n",
      "         0.0958, 0.1211],\n",
      "        [0.0066, 0.0094, 0.0150, 0.0170, 0.0172, 0.0188, 0.0150, 0.0180, 0.0154,\n",
      "         0.0181, 0.0166, 0.0182, 0.0183, 0.0185, 0.0200, 0.0199, 0.0215, 0.0210,\n",
      "         0.0232, 0.0217, 0.0252, 0.0227, 0.0275, 0.0241, 0.0299, 0.0259, 0.0325,\n",
      "         0.0285, 0.0364, 0.0314, 0.0419, 0.0343, 0.0468, 0.0367, 0.0479, 0.0385,\n",
      "         0.0475, 0.0400, 0.0444, 0.0420, 0.0428, 0.0441, 0.0445, 0.0469, 0.0478,\n",
      "         0.0501, 0.0504, 0.0541, 0.0516, 0.0583, 0.0543, 0.0611, 0.0586, 0.0638,\n",
      "         0.0617, 0.0697, 0.0678, 0.0756, 0.0731, 0.0833, 0.0789, 0.0546, 0.0472,\n",
      "         0.0449, 0.0474, 0.0536, 0.0548, 0.0504, 0.0489, 0.0473, 0.0496, 0.0487,\n",
      "         0.0514, 0.0555, 0.0533, 0.0427, 0.0364, 0.0392, 0.0428, 0.0457, 0.0451,\n",
      "         0.0462, 0.0472, 0.0515, 0.0535, 0.0504, 0.0522, 0.0525, 0.0532, 0.0589,\n",
      "         0.0651, 0.0829]])\n",
      "tensor([[0.0318, 0.0230, 0.0466, 0.0325, 0.0363, 0.0321, 0.0412, 0.0377, 0.0415,\n",
      "         0.0470, 0.0519, 0.0674, 0.0674, 0.0671, 0.0705, 0.0611, 0.0791, 0.0712,\n",
      "         0.0909, 0.0963, 0.1079, 0.1103, 0.1211, 0.1134, 0.1326, 0.1057, 0.1455,\n",
      "         0.1268, 0.1589, 0.1360, 0.1647, 0.1611, 0.2552, 0.2027, 0.2166, 0.2370,\n",
      "         0.1721, 0.2320, 0.1826, 0.2492, 0.1856, 0.2135, 0.1968, 0.2076, 0.2184,\n",
      "         0.2430, 0.2403, 0.2481, 0.2608, 0.2602, 0.2821, 0.3582, 0.2816, 0.4148,\n",
      "         0.3077, 0.4850, 0.2816, 0.4631, 0.3486, 0.4987, 0.6966, 0.3606, 0.6549,\n",
      "         0.3697, 0.4118, 0.3763, 0.3320, 0.3340, 0.2822, 0.2582, 0.2525, 0.2904,\n",
      "         0.3275, 0.2889, 0.2629, 0.2337, 0.2003, 0.1945, 0.2259, 0.3014, 0.3246,\n",
      "         0.3089, 0.2920, 0.2805, 0.2877, 0.3224, 0.3221, 0.3612, 0.3907, 0.3968,\n",
      "         0.4050, 0.8556],\n",
      "        [0.0350, 0.0318, 0.0630, 0.0520, 0.0696, 0.0616, 0.0578, 0.0668, 0.0730,\n",
      "         0.0758, 0.0697, 0.0682, 0.0726, 0.0657, 0.0796, 0.0705, 0.0925, 0.0828,\n",
      "         0.0988, 0.0954, 0.1139, 0.1110, 0.1253, 0.1259, 0.1313, 0.1395, 0.1363,\n",
      "         0.1524, 0.1776, 0.1611, 0.2204, 0.1570, 0.2123, 0.1600, 0.1801, 0.1680,\n",
      "         0.1736, 0.1912, 0.1518, 0.2118, 0.1621, 0.2255, 0.1780, 0.2366, 0.1967,\n",
      "         0.2417, 0.2140, 0.2516, 0.2262, 0.2641, 0.2495, 0.2666, 0.2771, 0.3314,\n",
      "         0.2924, 0.3322, 0.3272, 0.4404, 0.3296, 0.5368, 0.3147, 0.2337, 0.2041,\n",
      "         0.2023, 0.2318, 0.2630, 0.2584, 0.2382, 0.2877, 0.2782, 0.2391, 0.1885,\n",
      "         0.2124, 0.2715, 0.2915, 0.3390, 0.1840, 0.1701, 0.1575, 0.1815, 0.2167,\n",
      "         0.2037, 0.1955, 0.2022, 0.2390, 0.2309, 0.2140, 0.2156, 0.2251, 0.3541,\n",
      "         0.3956, 0.5851]])\n",
      "tensor([[4.5896e-06, 1.5259e-05, 1.7375e-05, 6.9395e-05, 1.1764e-04, 1.1891e-05,\n",
      "         9.3037e-05, 2.5332e-05, 3.0608e-04, 1.2126e-04, 3.4943e-05, 1.6709e-04,\n",
      "         4.8548e-05, 7.4968e-05, 8.7023e-06, 5.2840e-05, 3.9339e-06, 6.5565e-05,\n",
      "         6.3062e-05, 9.0957e-05, 7.4983e-05, 1.4412e-04, 8.4639e-06, 1.3542e-04,\n",
      "         1.2875e-05, 3.2306e-05, 4.3988e-05, 2.0373e-04, 4.2200e-05, 8.3089e-05,\n",
      "         8.0109e-05, 1.7858e-04, 1.1110e-04, 3.5882e-05, 5.7220e-06, 1.3590e-05,\n",
      "         8.9169e-05, 9.7275e-05, 7.5233e-04, 5.7924e-04, 8.0943e-05, 1.7178e-04,\n",
      "         1.4901e-05, 1.1396e-04, 1.5295e-04, 2.1112e-04, 3.4094e-05, 6.7949e-06,\n",
      "         7.2718e-05, 1.0014e-04, 8.4639e-05, 1.8120e-05, 1.3351e-05, 8.6069e-05,\n",
      "         8.5354e-05, 4.5824e-04, 7.6175e-05, 5.7220e-05, 6.9666e-04, 3.0041e-05,\n",
      "         1.4353e-04, 2.3723e-05, 2.5403e-04, 3.7742e-04, 1.4591e-04, 2.9922e-05,\n",
      "         1.0335e-04, 1.1730e-04, 7.7367e-05, 6.7925e-04, 5.8353e-05, 9.5773e-04,\n",
      "         3.1257e-04, 1.5742e-04, 6.9529e-05, 4.1008e-05, 5.6273e-04, 2.3776e-04,\n",
      "         1.2815e-04, 1.7762e-05, 1.0683e-04, 6.2749e-05, 7.8082e-06, 1.1444e-04,\n",
      "         1.0669e-04, 6.4147e-04, 1.6755e-04, 1.9765e-04, 1.1170e-04, 1.2755e-05,\n",
      "         3.1126e-04, 1.0574e-04],\n",
      "        [1.5993e-04, 4.8278e-04, 4.8172e-04, 2.2915e-04, 1.8233e-04, 1.1805e-04,\n",
      "         4.1723e-07, 1.3864e-04, 5.3585e-05, 1.9956e-04, 1.2517e-06, 1.9521e-04,\n",
      "         2.1935e-05, 9.7036e-05, 1.5140e-04, 2.9981e-05, 1.6570e-05, 7.5698e-05,\n",
      "         1.1683e-05, 3.0875e-05, 2.1577e-05, 4.6015e-05, 8.5354e-05, 4.8876e-05,\n",
      "         8.9407e-05, 2.1362e-04, 1.4448e-04, 9.5367e-07, 8.2254e-05, 5.4836e-05,\n",
      "         8.9645e-05, 1.1420e-04, 1.0896e-04, 1.3828e-05, 2.4486e-04, 4.9591e-05,\n",
      "         1.3113e-05, 1.6809e-04, 2.4700e-04, 7.4863e-05, 1.7548e-04, 8.7500e-05,\n",
      "         4.3392e-05, 2.3460e-04, 1.1969e-04, 2.9087e-05, 1.5712e-04, 3.1948e-05,\n",
      "         5.5552e-05, 1.2875e-05, 1.8454e-04, 4.1962e-05, 2.8610e-06, 1.9550e-04,\n",
      "         1.1754e-04, 3.2759e-04, 3.0279e-04, 3.7241e-04, 1.5974e-04, 1.2875e-05,\n",
      "         1.3289e-03, 3.0041e-05, 2.7275e-04, 9.0265e-04, 3.3331e-04, 1.5926e-04,\n",
      "         2.8133e-05, 4.6301e-04, 1.9073e-05, 9.3460e-05, 2.3508e-04, 2.1029e-04,\n",
      "         7.2479e-05, 8.2016e-05, 2.5129e-04, 1.6689e-05, 1.9073e-04, 2.3794e-04,\n",
      "         5.0545e-05, 1.8597e-04, 1.1587e-04, 3.7527e-04, 1.7262e-04, 5.9795e-04,\n",
      "         1.0490e-04, 1.2732e-04, 1.7643e-04, 4.9114e-05, 6.9618e-05, 1.4400e-04,\n",
      "         6.1989e-05, 4.1842e-04]])\n",
      "tensor([[[0.0247, 0.0139, 0.0338, 0.0182, 0.0251, 0.0246, 0.0228, 0.0260,\n",
      "          0.0315, 0.0254, 0.0297, 0.0365, 0.0335, 0.0337, 0.0291, 0.0341,\n",
      "          0.0298, 0.0361, 0.0322, 0.0435, 0.0355, 0.0395, 0.0352, 0.0397,\n",
      "          0.0394, 0.0418, 0.0466, 0.0513, 0.0591, 0.0574, 0.0724, 0.0588,\n",
      "          0.0759, 0.0588, 0.0875, 0.0695, 0.1005, 0.0874, 0.1137, 0.1061,\n",
      "          0.1092, 0.1077, 0.1093, 0.1177, 0.1090, 0.1158, 0.1095, 0.1358,\n",
      "          0.1171, 0.1322, 0.1184, 0.1326, 0.1277, 0.1489, 0.1307, 0.1617,\n",
      "          0.1539, 0.1717, 0.1548, 0.2021, 0.1797, 0.1735, 0.1745, 0.1595,\n",
      "          0.1551, 0.1389, 0.1429, 0.1385, 0.1447, 0.1325, 0.1263, 0.1329,\n",
      "          0.1417, 0.1415, 0.1382, 0.1327, 0.1315, 0.1395, 0.1391, 0.1329,\n",
      "          0.1385, 0.1502, 0.1483, 0.1504, 0.1661, 0.1694, 0.1708, 0.1775,\n",
      "          0.1937, 0.1933, 0.2049, 0.2209],\n",
      "         [0.0273, 0.0255, 0.0440, 0.0351, 0.0457, 0.0392, 0.0310, 0.0372,\n",
      "          0.0359, 0.0398, 0.0343, 0.0406, 0.0385, 0.0390, 0.0410, 0.0382,\n",
      "          0.0449, 0.0420, 0.0502, 0.0418, 0.0515, 0.0436, 0.0540, 0.0494,\n",
      "          0.0579, 0.0543, 0.0621, 0.0593, 0.0723, 0.0622, 0.0792, 0.0703,\n",
      "          0.0922, 0.0775, 0.1008, 0.0764, 0.1007, 0.0773, 0.0905, 0.0807,\n",
      "          0.0847, 0.0880, 0.0947, 0.0945, 0.0982, 0.1007, 0.1106, 0.1130,\n",
      "          0.1252, 0.1229, 0.1209, 0.1331, 0.1297, 0.1372, 0.1438, 0.1390,\n",
      "          0.1580, 0.1481, 0.1564, 0.1591, 0.1764, 0.1198, 0.1111, 0.1014,\n",
      "          0.1027, 0.1162, 0.1163, 0.1095, 0.1084, 0.1047, 0.1104, 0.1046,\n",
      "          0.1063, 0.1202, 0.1249, 0.0806, 0.0815, 0.0839, 0.0929, 0.1019,\n",
      "          0.0907, 0.0972, 0.0951, 0.1094, 0.1173, 0.1146, 0.1153, 0.1096,\n",
      "          0.0984, 0.1121, 0.1253, 0.1507]],\n",
      "\n",
      "        [[0.0095, 0.0045, 0.0108, 0.0061, 0.0093, 0.0111, 0.0064, 0.0103,\n",
      "          0.0157, 0.0093, 0.0083, 0.0188, 0.0089, 0.0124, 0.0091, 0.0109,\n",
      "          0.0103, 0.0114, 0.0104, 0.0150, 0.0110, 0.0128, 0.0115, 0.0131,\n",
      "          0.0122, 0.0123, 0.0143, 0.0166, 0.0189, 0.0153, 0.0219, 0.0175,\n",
      "          0.0227, 0.0202, 0.0217, 0.0214, 0.0270, 0.0248, 0.0314, 0.0260,\n",
      "          0.0320, 0.0252, 0.0348, 0.0257, 0.0329, 0.0290, 0.0316, 0.0364,\n",
      "          0.0364, 0.0395, 0.0313, 0.0396, 0.0364, 0.0395, 0.0364, 0.0371,\n",
      "          0.0391, 0.0408, 0.0457, 0.0452, 0.0518, 0.0509, 0.0468, 0.0536,\n",
      "          0.0460, 0.0418, 0.0442, 0.0462, 0.0441, 0.0493, 0.0460, 0.0444,\n",
      "          0.0407, 0.0415, 0.0395, 0.0381, 0.0389, 0.0387, 0.0384, 0.0410,\n",
      "          0.0401, 0.0439, 0.0418, 0.0448, 0.0463, 0.0441, 0.0424, 0.0494,\n",
      "          0.0477, 0.0499, 0.0499, 0.0502],\n",
      "         [0.0187, 0.0118, 0.0240, 0.0131, 0.0218, 0.0139, 0.0091, 0.0109,\n",
      "          0.0134, 0.0110, 0.0094, 0.0117, 0.0106, 0.0113, 0.0115, 0.0119,\n",
      "          0.0119, 0.0129, 0.0137, 0.0131, 0.0147, 0.0126, 0.0157, 0.0145,\n",
      "          0.0175, 0.0148, 0.0173, 0.0157, 0.0179, 0.0170, 0.0203, 0.0185,\n",
      "          0.0241, 0.0203, 0.0241, 0.0215, 0.0258, 0.0241, 0.0261, 0.0235,\n",
      "          0.0285, 0.0237, 0.0300, 0.0254, 0.0297, 0.0279, 0.0315, 0.0267,\n",
      "          0.0367, 0.0264, 0.0341, 0.0288, 0.0335, 0.0320, 0.0344, 0.0345,\n",
      "          0.0397, 0.0400, 0.0439, 0.0396, 0.0429, 0.0419, 0.0345, 0.0373,\n",
      "          0.0289, 0.0371, 0.0298, 0.0267, 0.0239, 0.0223, 0.0252, 0.0240,\n",
      "          0.0280, 0.0276, 0.0268, 0.0229, 0.0272, 0.0275, 0.0255, 0.0219,\n",
      "          0.0210, 0.0244, 0.0270, 0.0269, 0.0260, 0.0233, 0.0304, 0.0275,\n",
      "          0.0295, 0.0289, 0.0360, 0.0442]],\n",
      "\n",
      "        [[0.0008, 0.0004, 0.0016, 0.0009, 0.0005, 0.0017, 0.0007, 0.0015,\n",
      "          0.0022, 0.0012, 0.0010, 0.0021, 0.0009, 0.0014, 0.0011, 0.0012,\n",
      "          0.0008, 0.0011, 0.0010, 0.0017, 0.0009, 0.0017, 0.0011, 0.0014,\n",
      "          0.0016, 0.0014, 0.0013, 0.0018, 0.0025, 0.0017, 0.0018, 0.0015,\n",
      "          0.0021, 0.0019, 0.0022, 0.0021, 0.0019, 0.0014, 0.0033, 0.0035,\n",
      "          0.0023, 0.0019, 0.0029, 0.0026, 0.0033, 0.0031, 0.0038, 0.0030,\n",
      "          0.0028, 0.0034, 0.0026, 0.0038, 0.0040, 0.0043, 0.0032, 0.0042,\n",
      "          0.0026, 0.0034, 0.0055, 0.0035, 0.0032, 0.0049, 0.0032, 0.0057,\n",
      "          0.0044, 0.0028, 0.0046, 0.0054, 0.0042, 0.0043, 0.0031, 0.0061,\n",
      "          0.0041, 0.0021, 0.0021, 0.0023, 0.0044, 0.0042, 0.0035, 0.0019,\n",
      "          0.0028, 0.0030, 0.0031, 0.0055, 0.0053, 0.0035, 0.0030, 0.0035,\n",
      "          0.0031, 0.0071, 0.0056, 0.0044],\n",
      "         [0.0065, 0.0022, 0.0032, 0.0010, 0.0021, 0.0012, 0.0009, 0.0008,\n",
      "          0.0012, 0.0013, 0.0011, 0.0018, 0.0008, 0.0012, 0.0015, 0.0010,\n",
      "          0.0013, 0.0015, 0.0011, 0.0015, 0.0011, 0.0013, 0.0012, 0.0015,\n",
      "          0.0023, 0.0018, 0.0017, 0.0017, 0.0013, 0.0013, 0.0023, 0.0017,\n",
      "          0.0027, 0.0019, 0.0024, 0.0015, 0.0027, 0.0022, 0.0025, 0.0024,\n",
      "          0.0025, 0.0025, 0.0020, 0.0024, 0.0016, 0.0031, 0.0029, 0.0029,\n",
      "          0.0028, 0.0024, 0.0030, 0.0030, 0.0034, 0.0042, 0.0030, 0.0039,\n",
      "          0.0046, 0.0033, 0.0048, 0.0036, 0.0044, 0.0041, 0.0035, 0.0037,\n",
      "          0.0035, 0.0045, 0.0023, 0.0023, 0.0016, 0.0008, 0.0025, 0.0015,\n",
      "          0.0024, 0.0021, 0.0021, 0.0019, 0.0025, 0.0028, 0.0022, 0.0017,\n",
      "          0.0015, 0.0023, 0.0027, 0.0029, 0.0033, 0.0025, 0.0028, 0.0042,\n",
      "          0.0018, 0.0025, 0.0027, 0.0036]]])\n",
      "tensor(0.0480) tensor(0.0459)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_244/1859510098.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x, device=device) # x.to(device)\n",
      "/tmp/ipykernel_244/1859510098.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, device=device)\n",
      "/tmp/ipykernel_244/1859510098.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  z = torch.tensor(z, device=device)\n"
     ]
    }
   ],
   "source": [
    "Forward_Model.load_para_sup()\n",
    "err_mean, err_std = test_FM(Forward_Model, dataset_T)\n",
    "print(err_mean, err_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.6675e-01,  4.8080e-02, -2.3354e-01, -3.2537e-04, -2.2117e-01,\n",
      "          -1.1583e-01, -1.4750e-01, -3.6622e-01, -2.6865e-02, -7.3794e-01,\n",
      "           7.1534e-02, -1.2144e+00,  1.7536e-01, -1.8057e+00,  3.0486e-01,\n",
      "          -2.3247e+00,  4.9611e-01, -2.6890e+00,  7.0414e-01, -3.1587e+00,\n",
      "           8.9178e-01, -3.4436e+00,  1.0413e+00, -3.3143e+00,  1.1463e+00,\n",
      "          -2.6680e+00,  1.2334e+00, -1.6627e+00,  1.3667e+00, -7.3424e-01,\n",
      "           1.5868e+00, -3.6029e-01,  1.8900e+00, -2.4546e-01,  2.2503e+00,\n",
      "          -2.7555e-01,  2.6248e+00, -2.6100e-01,  2.9327e+00, -1.7228e-01,\n",
      "           3.1716e+00, -1.7399e-01,  3.3772e+00, -4.5975e-01,  3.5024e+00,\n",
      "          -9.6460e-01,  3.4526e+00, -1.4400e+00,  3.1929e+00, -1.3165e+00,\n",
      "           2.8034e+00, -5.8132e-01,  2.4184e+00,  2.2955e-01,  2.1507e+00,\n",
      "           7.5141e-01,  2.0038e+00,  5.3017e-01,  2.0271e+00, -2.7533e-01,\n",
      "           2.1479e+00,  2.2445e+00,  2.2200e+00,  2.1803e+00,  1.9143e+00,\n",
      "           1.8649e+00,  1.6908e+00,  1.4894e+00,  1.1967e+00,  8.9424e-01,\n",
      "           6.5623e-01,  5.9877e-01,  6.8531e-01,  8.4356e-01,  1.0194e+00,\n",
      "           1.1727e+00,  1.2350e+00,  1.2866e+00,  1.4333e+00,  1.6397e+00,\n",
      "           1.7854e+00,  1.8001e+00,  1.7027e+00,  1.3362e+00,  6.7882e-01,\n",
      "           9.4027e-02, -4.0369e-01, -1.0248e+00, -1.4183e+00, -1.3882e+00,\n",
      "          -1.1666e+00, -1.0111e+00],\n",
      "         [ 1.5347e-01,  9.5324e-02,  2.8279e-01,  1.7930e-01,  4.1637e-01,\n",
      "           2.6795e-01,  5.8487e-01,  3.8911e-01,  7.5983e-01,  4.8860e-01,\n",
      "           9.2246e-01,  5.4381e-01,  1.0958e+00,  5.7434e-01,  1.2613e+00,\n",
      "           6.5376e-01,  1.4359e+00,  7.6766e-01,  1.6192e+00,  9.2469e-01,\n",
      "           1.8443e+00,  1.0242e+00,  2.0872e+00,  9.7871e-01,  2.3308e+00,\n",
      "           7.6184e-01,  2.5778e+00,  4.3442e-01,  2.8150e+00,  1.6387e-01,\n",
      "           3.0151e+00,  1.0994e-01,  3.1524e+00,  1.5450e-01,  3.2086e+00,\n",
      "           2.0343e-01,  3.1767e+00,  2.3513e-01,  3.0813e+00,  2.7379e-01,\n",
      "           2.9257e+00,  3.5983e-01,  2.6741e+00,  5.5353e-01,  2.3280e+00,\n",
      "           8.8750e-01,  1.9626e+00,  1.3036e+00,  1.6510e+00,  1.7853e+00,\n",
      "           1.4047e+00,  2.3437e+00,  1.2277e+00,  2.8910e+00,  1.1371e+00,\n",
      "           3.3333e+00,  1.1407e+00,  3.5616e+00,  1.2591e+00,  3.5439e+00,\n",
      "           1.3026e+00,  1.6747e+00,  2.0971e+00,  2.4451e+00,  2.7340e+00,\n",
      "           2.8728e+00,  2.9749e+00,  3.0326e+00,  3.0415e+00,  2.9982e+00,\n",
      "           2.9613e+00,  2.9583e+00,  2.9929e+00,  3.0518e+00,  3.1128e+00,\n",
      "           3.1554e+00,  3.1814e+00,  3.1854e+00,  3.1673e+00,  3.1487e+00,\n",
      "           3.1437e+00,  3.1648e+00,  3.2054e+00,  3.2619e+00,  3.3332e+00,\n",
      "           3.3828e+00,  3.4164e+00,  3.4611e+00,  3.4850e+00,  3.4536e+00,\n",
      "           3.4288e+00,  3.4086e+00]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-1.5391e-01,  1.2661e-01, -2.3123e-01,  1.2198e-01, -2.8765e-01,\n",
      "           7.4340e-02, -3.5963e-01, -2.7413e-02, -3.2892e-01, -1.6387e-01,\n",
      "          -2.8470e-01, -2.8960e-01, -2.1915e-01, -4.1897e-01, -1.5176e-01,\n",
      "          -5.1663e-01, -9.1755e-02, -6.1811e-01, -3.6079e-02, -7.2629e-01,\n",
      "           3.3252e-02, -8.1675e-01,  1.3943e-01, -9.0324e-01,  2.6990e-01,\n",
      "          -9.8009e-01,  4.1110e-01, -1.0642e+00,  5.5721e-01, -1.1408e+00,\n",
      "           7.1240e-01, -1.2078e+00,  8.7350e-01, -1.2725e+00,  1.0300e+00,\n",
      "          -1.3421e+00,  1.1778e+00, -1.4233e+00,  1.3178e+00, -1.5193e+00,\n",
      "           1.4593e+00, -1.6192e+00,  1.6161e+00, -1.7170e+00,  1.7924e+00,\n",
      "          -1.7957e+00,  1.9808e+00, -1.8782e+00,  2.1916e+00, -1.9512e+00,\n",
      "           2.4655e+00, -2.0328e+00,  2.7491e+00, -2.1655e+00,  3.0091e+00,\n",
      "          -2.3431e+00,  3.2013e+00, -2.6134e+00,  3.3386e+00, -2.9004e+00,\n",
      "           3.4350e+00,  3.3295e+00,  3.0902e+00,  2.7339e+00,  2.3755e+00,\n",
      "           2.1815e+00,  1.9650e+00,  1.8002e+00,  1.6343e+00,  1.4463e+00,\n",
      "           1.2145e+00,  9.3211e-01,  6.5535e-01,  3.4203e-01, -2.8373e-03,\n",
      "          -3.5226e-01, -6.9447e-01, -1.0438e+00, -1.4157e+00, -1.8004e+00,\n",
      "          -2.1527e+00, -2.4713e+00, -2.7172e+00, -2.8595e+00, -2.9841e+00,\n",
      "          -3.1235e+00, -3.3664e+00, -3.6088e+00, -3.8149e+00, -3.9965e+00,\n",
      "          -3.9870e+00, -3.2859e+00],\n",
      "         [ 1.5101e-01,  7.6627e-02,  2.7570e-01,  1.4158e-01,  4.0930e-01,\n",
      "           1.8700e-01,  5.6745e-01,  2.3486e-01,  7.1578e-01,  2.7397e-01,\n",
      "           8.4365e-01,  3.0635e-01,  9.7222e-01,  3.4757e-01,  1.0921e+00,\n",
      "           3.8542e-01,  1.2100e+00,  4.1061e-01,  1.3247e+00,  4.2801e-01,\n",
      "           1.4554e+00,  4.4662e-01,  1.5934e+00,  4.8157e-01,  1.7413e+00,\n",
      "           5.3539e-01,  1.8917e+00,  5.9983e-01,  2.0338e+00,  6.5590e-01,\n",
      "           2.1600e+00,  6.9611e-01,  2.2638e+00,  7.2137e-01,  2.3439e+00,\n",
      "           7.3598e-01,  2.4030e+00,  7.4422e-01,  2.4444e+00,  7.5070e-01,\n",
      "           2.4682e+00,  7.5934e-01,  2.4705e+00,  7.7355e-01,  2.4454e+00,\n",
      "           7.8954e-01,  2.4025e+00,  7.9789e-01,  2.3454e+00,  8.0999e-01,\n",
      "           2.2558e+00,  8.2086e-01,  2.1556e+00,  8.3691e-01,  2.0751e+00,\n",
      "           8.3455e-01,  2.0359e+00,  8.4116e-01,  2.0609e+00,  8.8625e-01,\n",
      "           2.0573e+00,  2.3755e+00,  2.6410e+00,  2.8982e+00,  3.1671e+00,\n",
      "           3.3940e+00,  3.6460e+00,  3.8611e+00,  4.0288e+00,  4.1944e+00,\n",
      "           4.3697e+00,  4.5365e+00,  4.6731e+00,  4.7685e+00,  4.8268e+00,\n",
      "           4.8505e+00,  4.8390e+00,  4.8051e+00,  4.7591e+00,  4.6995e+00,\n",
      "           4.6203e+00,  4.5229e+00,  4.3790e+00,  4.1796e+00,  3.9211e+00,\n",
      "           3.6027e+00,  3.2335e+00,  2.8160e+00,  2.3249e+00,  1.8191e+00,\n",
      "           1.3826e+00,  1.0065e+00]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "Forward_Model.load_para()\n",
    "samran = torch.randn(1, 1, 32, 32, device=device)\n",
    "samran2 = torch.randn(1, 1, 32, 32, device=device)*10\n",
    "yp1 = Forward_Model.network(samran)\n",
    "yp2 = Forward_Model.network(samran2)\n",
    "o1 = obs(yp1)\n",
    "o2 = obs(yp2)\n",
    "print(o1)\n",
    "print(o2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
